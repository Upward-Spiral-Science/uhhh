{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delaunay\n",
    "Here, we'll perform various analysis by constructing graphs and measure properties of those graphs to learn more about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.spatial import Delaunay\n",
    "import numpy as np\n",
    "import math\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage import future\n",
    "import networkx as nx\n",
    "from ragGen import *\n",
    "%matplotlib inline\n",
    "sns.set_color_codes(\"pastel\")\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data = open('../../data/data.csv', 'r').readlines()\n",
    "fieldnames = ['x', 'y', 'z', 'unmasked', 'synapses']\n",
    "reader = csv.reader(data)\n",
    "reader.next()\n",
    "\n",
    "rows = [[int(col) for col in row] for row in reader]\n",
    "\n",
    "# These will come in handy later\n",
    "sorted_x = sorted(list(set([r[0] for r in rows])))\n",
    "sorted_y = sorted(list(set([r[1] for r in rows])))\n",
    "sorted_z = sorted(list(set([r[2] for r in rows])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with just looking at analysis in euclidian space, then thinking about weighing by synaptic density later. Since we hypothesize that our data will show that tissue varies as we move down the y-axis (z-axis in brain) through cortical layers, an interesting thing to do would be compare properties of the graphs on each layer (ie how does graph connectivity vary as we move through layers).\n",
    "\n",
    "Let's start by triangulating our data. We'll use Delaunay on each y layer first. Putting our data in the right format for doing graph analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array(rows)\n",
    "b = np.delete(a, np.s_[3::],1)\n",
    "\n",
    "# Separate layers - have to do some wonky stuff to get this to work\n",
    "b = sorted(b, key=lambda e: e[1])\n",
    "b = np.array([v.tolist() for v in b])\n",
    "b = np.split(b, np.where(np.diff(b[:,1]))[0]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that our data is in the right format, we'll create 52 delaunay graphs. Then we'll perform analyses on these graphs. A simple but useful metric would be to analyze edge length distributions in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphs = []\n",
    "centroid_list = []\n",
    "\n",
    "for layer in b:\n",
    "    centroids = np.array(layer)\n",
    "    \n",
    "    # get rid of the y value - not relevant anymore\n",
    "    centroids = np.delete(centroids, 1, 1)\n",
    "    centroid_list.append(centroids)\n",
    "    \n",
    "    graph = Delaunay(centroids)\n",
    "    graphs.append(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to need a method to get edge lengths from 2D centroid pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_d_edge_length(edge):\n",
    "    (x1, y1), (x2, y2) = edge\n",
    "    return math.sqrt((x2-x1)**2 + (y2-y1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge_length_list = [[]]\n",
    "tri_area_list = [[]]\n",
    "\n",
    "for del_graph in graphs:\n",
    "    \n",
    "    tri_areas = []\n",
    "    edge_lengths = []\n",
    "    triangles = []\n",
    "\n",
    "    for t in centroids[del_graph.simplices]:\n",
    "        triangles.append(t)\n",
    "        a, b, c = [tuple(map(int,list(v))) for v in t]\n",
    "        edge_lengths.append(get_d_edge_length((a,b)))\n",
    "        edge_lengths.append(get_d_edge_length((a,c)))\n",
    "        edge_lengths.append(get_d_edge_length((b,c)))\n",
    "        try:\n",
    "            tri_areas.append(float(Triangle(a,b,c).area))\n",
    "        except:\n",
    "            continue\n",
    "    edge_length_list.append(edge_lengths)\n",
    "    tri_area_list.append(tri_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizing after all this that simply location is useless. We know the voxels are evenly spaced, which means our edge length data will be all the same. See that the \"centroids\" are no different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       ..., \n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.subtract(centroid_list[0], centroid_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no distance between the two. Therefore it is perhaps more useful to consider a graph that considers node weights. Voronoi is dual to Delaunay, so that's not much of an option. We want something that considers both spacial location and density similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we look at the default networkx graph plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_volume = np.zeros((len(sorted_x), len(sorted_y), len(sorted_z)))\n",
    "for r in rows:\n",
    "    real_volume[sorted_x.index(r[0]), sorted_y.index(r[1]), sorted_z.index(r[2])] = r[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NetworkXError",
     "evalue": "Input is not a known data type for conversion.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-23035561684b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnx_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnx_graphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/networkx/classes/graph.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, **attr)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# attempt to load graph with data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_networkx_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_using\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;31m# load graph attributes (must be after convert)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/networkx/convert.pyc\u001b[0m in \u001b[0;36mto_networkx_graph\u001b[0;34m(data, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     raise nx.NetworkXError(\\\n\u001b[0;32m--> 170\u001b[0;31m           \"Input is not a known data type for conversion.\")\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNetworkXError\u001b[0m: Input is not a known data type for conversion."
     ]
    }
   ],
   "source": [
    "nx_graphs = []\n",
    "for layer in b:\n",
    "    G = nx.Graph(graph)\n",
    "    nx_graphs.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for graph in nx_graphs:\n",
    "    plt.figure()\n",
    "    nx.draw(graph, node_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the spring layout, so we're losing positional information. We can improve the plot by adding position information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_self_loops = []\n",
    "for rag in y_rags:\n",
    "    num_self_loops.append(rag.number_of_selfloops())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_self_loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. There are no self loops. Why would this be? Let's come back to this. In the meantime, I want to give some though to what it means to have a self loop, whether it should be theoretically possible given our data, and whether our graphs are formed properly.\n",
    "\n",
    "The answer to this question is very simple. In a RAG, there are no self-loops by definition. Self loops are edges that form a connection between a node and itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../docs/figures/selfloop.png\" width=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether the graphs are formed properly, let's look at an adjacency lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_rags[0].adjacency_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test Data\n",
    "test = np.array([[1,2],[3,4]])\n",
    "test_rag = skimage.future.graph.RAG(test)\n",
    "test_rag.adjacency_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_volume_x = np.zeros((len(sorted_x), len(sorted_y), len(sorted_z)))\n",
    "for r in rows:\n",
    "    real_volume_x[ sorted_x.index(r[0]), sorted_y.index(r[1]), sorted_z.index(r[2])] = r[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_rags = []\n",
    "count = 0;\n",
    "for layer in real_volume_x:\n",
    "    count = count + 1\n",
    "    x_rags.append(skimage.future.graph.RAG(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_edges_x = []\n",
    "for rag in x_rags:\n",
    "    num_edges_x.append(rag.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=range(len(num_edges_x)), y=num_edges_x)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here the number of edges is low in that area that does not have many synapses. It, as expected, mirrors the distribution of synapses. It appears to be approximately uniform at the top, with buffers of very few synapses on the sides. Remember from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.amax(real_volume, axis=2), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# edge_length_list[3]\n",
    "# tri_area_list[3]\n",
    "# triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note for future\n",
    "# del_features['d_edge_length_mean'] = np.mean(edge_lengths)\n",
    "# del_features['d_edge_length_std'] = np.std(edge_lengths)\n",
    "# del_features['d_edge_length_skew'] = scipy.stats.skew(edge_lengths)\n",
    "# del_features['d_edge_length_kurtosis'] = scipy.stats.kurtosis(edge_lengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
